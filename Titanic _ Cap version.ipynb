{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic\n",
    "\n",
    "### Problem description\n",
    "When the Titanic first set out, people believed the ship could not sink. However, the unthinkable happened. The titanic hit an iceberg ripping open half of its side leading to the sinking of the Titanic. Because no-one had expected this, there were insufficient life boats aboard the ship. \n",
    "\n",
    "From analysis it has shown that certain people on board were more likely to survive than others. This exercise will focus on developing a model which can predict survival on board of the Titanic\n",
    "\n",
    "### Variables in the titanic\n",
    "Variable  &  Definition                                                  \n",
    "survival  =  Survival    - key: 0 = No, 1 = Yes\n",
    "pclass\t  =  Ticket class - key: 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "sex\t      =  Sex\t\n",
    "Age\t      =  Age in years\t\n",
    "sibsp\t  =  # of siblings / spouses aboard the Titanic\t\n",
    "parch\t  =  # of parents / children aboard the Titanic\t\n",
    "ticket\t  =  Ticket number\t\n",
    "fare\t  =  Passenger fare\t\n",
    "cabin\t  =  Cabin number\t\n",
    "embarked  =  Port of Embarkation\t- key: C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "First, we import the relevant packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import tree, svm, neighbors, ensemble\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import the raw training data and put it in a DataFrame using pandas for further analysis. We show the first five rows of our training and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('C:/Users/marij/Documents/Python Scripts/train.csv')\n",
    "df_test = pd.read_csv('C:/Users/marij/Documents/Python Scripts/test.csv')\n",
    "df_full = [df_train, df_test]\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set has 12 variables. In the training data, all variables, except for 'Age', 'Embarked' and 'Cabin', consist of 891 observation. This means that 'Age', 'Embarked' and 'Cabin' have missing observations. The missing observations have been filled with NaN which python recognizes as 'not a number'. \n",
    "\n",
    "The test data also has 12 variables. Here 'Age', 'Cabin' and 'Fare' are incomplete and have less than 418 observations.\n",
    "\n",
    "- 'sex' and 'survived' are binary values, meaning they can only take two values. \n",
    "- 'Class','SibSp' and 'Parch' are discrete \n",
    "- 'Age' and 'Fare' are continuous\n",
    "- 'Ticket' and 'Cabin' are part numberical and part string\n",
    "- 'Name' and 'Embarked' are string variables\n",
    "- PassengerId gives all passenger a number from 1 to 891 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Even though 'Sex' can currently only take two values, male or female, it is classed as an object. We will convert this to male taking the value 0 and female taking the value 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dataset in df_full:\n",
    "    dataset['Sex_d'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next, we will fill the gaps in 'Age' and 'Fare' with the median of the series. We also fill the NaN values in 'Cabin' with a 0 (this will be used later to create a dummy). We fill the gaps in the 'Embarked' Series with an 'S' as Southampton is where most passengers embarked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dataset in df_full:\n",
    "    dataset['Age_c'] = dataset['Age'].fillna(dataset['Age'].median())\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())\n",
    "    dataset['Cabin'] = dataset['Cabin'].fillna(0)\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURES\n",
    "\n",
    "We now go through the different features showing how they influence survival chance on the Titanic. Where necessary we will adjust the features such that they become better usable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Survived\n",
       "0  female  0.742038\n",
       "1    male  0.188908"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we see that females were much more likely to survive than males. It also becomes clear that the survival chance for males was less than 20%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CITY EMBARKED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked_c</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.553571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.389610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.339009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Embarked_c  Survived\n",
       "0           0  0.553571\n",
       "1           1  0.389610\n",
       "2           2  0.339009"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We convert the 'Embarked' variable to an integer with classes C as 0, Q as 1 and S as 2.\n",
    "for dataset in df_full:\n",
    "    dataset['Embarked_c'] = dataset['Embarked'].map( {'C': 0, 'Q': 1,'S': 2} ).astype(int)\n",
    "\n",
    "df_train[['Embarked_c', 'Survived']].groupby(['Embarked_c'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we see that people who embarked in Cherbourg were more likely to survive than people who embarked in Queenstown or Southhampton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIBLINGS/SPOUSE ON-BOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.535885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.464286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.345395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SibSp  Survived\n",
       "1      1  0.535885\n",
       "2      2  0.464286\n",
       "0      0  0.345395\n",
       "3      3  0.250000\n",
       "4      4  0.166667\n",
       "5      5  0.000000\n",
       "6      8  0.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we see that people who were either with one sibling or their spouse had the highest chance of survival. Larger families (people who were with 5 or 8 siblings/spouse) had no chance of survival. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARENTS/CHILDREN ON-BOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parch</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.550847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.343658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parch  Survived\n",
       "3      3  0.600000\n",
       "1      1  0.550847\n",
       "2      2  0.500000\n",
       "0      0  0.343658\n",
       "5      5  0.200000\n",
       "4      4  0.000000\n",
       "6      6  0.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People who had three parents/children on board the largest chance of survival (60%) followed by people who had one or two parents/children. Also we see that people who had more family members (parents/children) on board had a lower chance of survival. Families of 5 had a 20% chance of survival and families of 4 and 6 did not survive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "FARE PAID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a categorical variable from fare. We find the maximum fare paid is 512.32920000000001 and the minimum fare paid is 0 using the 'df_train['Fare'].max()'and 'df_train['Fare'].min()' expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare_c</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.681250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.415094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.414815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.313084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.206731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fare_c  Survived\n",
       "5     5.0  0.681250\n",
       "3     3.0  0.415094\n",
       "4     4.0  0.414815\n",
       "2     2.0  0.313084\n",
       "1     1.0  0.206731\n",
       "0     0.0  0.066667"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in df_full:\n",
    "    dataset.loc[dataset['Fare'] <= 1, 'Fare_c'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 1) & (dataset['Fare'] <= 7.8958), 'Fare_c'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 7.8958) & (dataset['Fare'] <= 14), 'Fare_c'] = 2\n",
    "    dataset.loc[(dataset['Fare'] > 14) & (dataset['Fare'] <= 26), 'Fare_c'] = 3\n",
    "    dataset.loc[(dataset['Fare'] > 26) & (dataset['Fare'] <= 50), 'Fare_c'] = 4\n",
    "    dataset.loc[dataset['Fare'] > 50, 'Fare_c'] = 5\n",
    "df_train[['Fare_c', 'Survived']].groupby(['Fare_c'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We find that the people who paid the highest fare had the largest chance of surviving. There is barely any difference between category 3 and 4, both had a survival chance of about 41%. Category 2, who paid between ~8 and 14, had about 10% less chance of surviving than category 3 and 4. Category 1 who paid less between 1 and 8 had yet less chance of surviving (20%). Category 0, people who paid a fare of less than 1, had 7% chance of surviving. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASS OF THE FARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived\n",
       "0       1  0.629630\n",
       "1       2  0.472826\n",
       "2       3  0.242363"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that people in a better class (i.e. those who paid more) have a larger survival chance. \n",
    "This reiterates our earlier results and indicates that PClass and Fare are strongly negatively correlated, meaning that a higher fare means a lower class, which in this case means a better class. People with a higher fare and a lower (better) class also have a higher survival chance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHILDREN\n",
    "\n",
    "We create a dummy variable where people under 17 are classed as children and people older than 17 as adults. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Children</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.362832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Children  Survived\n",
       "0       0.0  0.550000\n",
       "1       1.0  0.362832"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in df_full:\n",
    "    dataset.loc[dataset['Age_c'] <= 16, 'Children'] = 0\n",
    "    dataset.loc[dataset['Age_c'] > 16, 'Children'] = 1\n",
    "\n",
    "df_train[['Children', 'Survived']].groupby(['Children'], as_index=False).mean().sort_values(by='Survived', ascending=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above it follows that children have a higher chance of surviving. \n",
    "\n",
    "Next we split the children and adult categories by gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Children2</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.754717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.673469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.431373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.165399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Children2  Survived\n",
       "3        3.0  0.754717\n",
       "0        0.0  0.673469\n",
       "1        1.0  0.431373\n",
       "2        2.0  0.165399"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in df_full:\n",
    "    dataset.loc[(dataset['Age_c'] <= 16) & (dataset['Sex_d'] == 1), 'Children2'] = 1\n",
    "    dataset.loc[(dataset['Age_c'] <= 16) & (dataset['Sex_d'] == 0), 'Children2'] = 0\n",
    "    dataset.loc[(dataset['Age_c'] > 16) & (dataset['Sex_d'] == 1), 'Children2'] = 2\n",
    "    dataset.loc[(dataset['Age_c'] > 16) & (dataset['Sex_d'] == 0), 'Children2'] = 3\n",
    "df_train[['Children2', 'Survived']].groupby(['Children2'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we see that adult males (group 2) have the lowest survival chance followed by boys (group 1). For females this is the other way around, adult females (group 3) have a higher survival chance than female children (group 0). Female children have a higher survival chance than male children. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CABIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For part of the passengers we have a cabin number, whereas for other we have a missing value. Here, we assume that those who don't have a cabin number slept in shared rooms. We will test this assumption by creating a dummy 'P_Cabin' or private cabin and seeing how this compares to the class of the fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>P_Cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.024440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   P_Cabin\n",
       "0       1  0.814815\n",
       "1       2  0.086957\n",
       "2       3  0.024440"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in df_full:\n",
    "    dataset.loc[dataset['Cabin'] != 0, 'Cabin'] = 1\n",
    "    dataset.loc[dataset['Age_c'] == 0, 'Cabin'] = 0\n",
    "\n",
    "cat_names = {1:'P_Cabin', 0:'S_Cabin'}\n",
    "for elem in df_train['Cabin'].unique():\n",
    "    df_train[cat_names[elem]] = df_train['Cabin'] == elem\n",
    "\n",
    "for elem in df_test['Cabin'].unique():\n",
    "    df_test[cat_names[elem]] = df_test['Cabin'] == elem\n",
    "\n",
    "df_train[['Pclass', 'P_Cabin']].groupby(['Pclass'], as_index=False).mean().sort_values(by='P_Cabin', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that when people had a first class ticket, they were by far the likeliest to also have a private cabin. People who paid for a second or third class ticket, were significantly more unlikely to have their own cabin.\n",
    "\n",
    "Below, we show that people who have a private cabin are more than double as likely to survive than people with a shared cabin are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.299854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cabin  Survived\n",
       "1      1  0.666667\n",
       "0      0  0.299854"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['Cabin', 'Survived']].groupby(['Cabin'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations between features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will plot a correlation matrix showing us the correlations between the different variables. This will also serve as a first explanation as to how well each variable (or passenger characteristic) explains the variation in survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['Age','Fare','Embarked', 'PassengerId', 'Name', 'Ticket','Sex', 'P_Cabin', 'S_Cabin', 'Age'], axis=1)\n",
    "df_test = df_test.drop(['Age','Fare','Embarked', 'PassengerId', 'Name', 'Ticket','Sex', 'P_Cabin', 'S_Cabin', 'Age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Sex_d</th>\n",
       "      <th>Age_c</th>\n",
       "      <th>Embarked_c</th>\n",
       "      <th>Fare_c</th>\n",
       "      <th>Children</th>\n",
       "      <th>Children2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>-0.543351</td>\n",
       "      <td>-0.064910</td>\n",
       "      <td>-0.167675</td>\n",
       "      <td>0.319799</td>\n",
       "      <td>-0.121485</td>\n",
       "      <td>0.208520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>-0.339898</td>\n",
       "      <td>0.162098</td>\n",
       "      <td>-0.685945</td>\n",
       "      <td>-0.128232</td>\n",
       "      <td>-0.181301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>-0.233296</td>\n",
       "      <td>0.068230</td>\n",
       "      <td>0.361810</td>\n",
       "      <td>-0.337773</td>\n",
       "      <td>-0.163184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>-0.172482</td>\n",
       "      <td>0.039798</td>\n",
       "      <td>0.351835</td>\n",
       "      <td>-0.334728</td>\n",
       "      <td>-0.119889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_d</th>\n",
       "      <td>-0.543351</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>-0.114631</td>\n",
       "      <td>-0.245489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.081163</td>\n",
       "      <td>0.108262</td>\n",
       "      <td>-0.238855</td>\n",
       "      <td>0.102403</td>\n",
       "      <td>-0.396768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_c</th>\n",
       "      <td>-0.064910</td>\n",
       "      <td>-0.339898</td>\n",
       "      <td>-0.233296</td>\n",
       "      <td>-0.172482</td>\n",
       "      <td>0.081163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018754</td>\n",
       "      <td>0.122257</td>\n",
       "      <td>0.583515</td>\n",
       "      <td>0.433274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_c</th>\n",
       "      <td>-0.167675</td>\n",
       "      <td>0.162098</td>\n",
       "      <td>0.068230</td>\n",
       "      <td>0.039798</td>\n",
       "      <td>0.108262</td>\n",
       "      <td>-0.018754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148561</td>\n",
       "      <td>-0.006079</td>\n",
       "      <td>-0.040336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_c</th>\n",
       "      <td>0.319799</td>\n",
       "      <td>-0.685945</td>\n",
       "      <td>0.361810</td>\n",
       "      <td>0.351835</td>\n",
       "      <td>-0.238855</td>\n",
       "      <td>0.122257</td>\n",
       "      <td>-0.148561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.123372</td>\n",
       "      <td>0.055183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Children</th>\n",
       "      <td>-0.121485</td>\n",
       "      <td>-0.128232</td>\n",
       "      <td>-0.337773</td>\n",
       "      <td>-0.334728</td>\n",
       "      <td>0.102403</td>\n",
       "      <td>0.583515</td>\n",
       "      <td>-0.006079</td>\n",
       "      <td>-0.123372</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Children2</th>\n",
       "      <td>0.208520</td>\n",
       "      <td>-0.181301</td>\n",
       "      <td>-0.163184</td>\n",
       "      <td>-0.119889</td>\n",
       "      <td>-0.396768</td>\n",
       "      <td>0.433274</td>\n",
       "      <td>-0.040336</td>\n",
       "      <td>0.055183</td>\n",
       "      <td>0.771406</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Survived    Pclass     SibSp     Parch     Sex_d     Age_c  \\\n",
       "Survived    1.000000 -0.338481 -0.035322  0.081629 -0.543351 -0.064910   \n",
       "Pclass     -0.338481  1.000000  0.083081  0.018443  0.131900 -0.339898   \n",
       "SibSp      -0.035322  0.083081  1.000000  0.414838 -0.114631 -0.233296   \n",
       "Parch       0.081629  0.018443  0.414838  1.000000 -0.245489 -0.172482   \n",
       "Sex_d      -0.543351  0.131900 -0.114631 -0.245489  1.000000  0.081163   \n",
       "Age_c      -0.064910 -0.339898 -0.233296 -0.172482  0.081163  1.000000   \n",
       "Embarked_c -0.167675  0.162098  0.068230  0.039798  0.108262 -0.018754   \n",
       "Fare_c      0.319799 -0.685945  0.361810  0.351835 -0.238855  0.122257   \n",
       "Children   -0.121485 -0.128232 -0.337773 -0.334728  0.102403  0.583515   \n",
       "Children2   0.208520 -0.181301 -0.163184 -0.119889 -0.396768  0.433274   \n",
       "\n",
       "            Embarked_c    Fare_c  Children  Children2  \n",
       "Survived     -0.167675  0.319799 -0.121485   0.208520  \n",
       "Pclass        0.162098 -0.685945 -0.128232  -0.181301  \n",
       "SibSp         0.068230  0.361810 -0.337773  -0.163184  \n",
       "Parch         0.039798  0.351835 -0.334728  -0.119889  \n",
       "Sex_d         0.108262 -0.238855  0.102403  -0.396768  \n",
       "Age_c        -0.018754  0.122257  0.583515   0.433274  \n",
       "Embarked_c    1.000000 -0.148561 -0.006079  -0.040336  \n",
       "Fare_c       -0.148561  1.000000 -0.123372   0.055183  \n",
       "Children     -0.006079 -0.123372  1.000000   0.771406  \n",
       "Children2    -0.040336  0.055183  0.771406   1.000000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFECAYAAABBI3d1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fc9d095e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(df_train.corr())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table shows the Pearson correlation coefficient between the different variables. We are mainly interested in how each of the different variables correlates with the variable 'Survived'. \n",
    "The 'Fare' (the fee paid) correlates strongly with 'Survived' (32%) as does the 'Pclass' (33.8%).\n",
    "Furthermore we see that 'Age' and 'Pclass' as well ass 'Pclass'and 'Fare' are highly correlated, 34% and 68.6% respectively. This correlation can easily be explained by the fact that slightly older people are likely to be richer and are thus able to afford a higher fare. In turn this means that they would be in a better class. \n",
    "Lastly, gender correlates highly with 'Survived' (54.3%) and 'Children' correlates highly with 'Children2'. The latter makes a lot of sense as 'Children2' is 'Children' divided by gender.\n",
    "\n",
    "The correlation plot shows us the same thing. Here, the darker the grey, the stronger two variables are correlated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start the modelling exercise, we first create an X and y numpy array for the training data and a X numpy array for the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = df_train['Survived'].ravel()\n",
    "df_train = df_train.drop(['Survived'], axis=1)\n",
    "X_train = df_train.values \n",
    "X_test = df_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCORING THE MODELS\n",
    "\n",
    "The 'score' method is used to judge the quality of fit of the model. The closer the score is to 1, the better the fit of the model. Next to the score method we also use the cross validation algorithm to test the accuracy of our model. The cross validation algorithm, by default, splits the data into three samples and tests how well the model fits to each of these samples. We compute the mean and standard deviation of the three scores obtained by the cross validation method to compare the models as well. We could specify the number of samples the data is split in by specifying the cv parameter which is set to 3 in the loogistic regression example.\n",
    "\n",
    "\n",
    "LOGISTIC REGRESSION\n",
    "\n",
    "The Titanic problem is a binary problem also known as a classification problem; we are trying to learn a model to predict whether a passenger died or survived. In a logistic regression we assess the probability that y=1 dependent on the features x. In this sense, logistic regression is a linear model and not necessarily a regression. Logistic regression takes the following form:\n",
    "\n",
    "Theta (x) = g(theta ^ T * x) or g(z) = 1 / (1 + e ^ (-z)) where e is the natural base of the logarithm. Similarly as for linear models, we can find the cost function for the above model description and optimize this. \n",
    "\n",
    "The form of this function means that the outcome can only be 0 or 1, hence this form of regression is only suitable for binary problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81369248035914699"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log = logreg.score(X_train, y_train)\n",
    "acc_log2 = cross_val_score(logreg, X_train, y_train, cv=3)\n",
    "m_acc_log2 = acc_log2.mean()\n",
    "sd_acc_log2 = acc_log2.std()\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPPORT VECTOR MACHINES (SVC) ALGORITHM\n",
    "\n",
    "The below uses the Support Vector Machines algorithm. The algorithm includes regression, classification and outlier detection methods. For the Titanic problem we use the SVC specification to perform multi-class classification on the data. \n",
    "\n",
    "The algorithm will class each data point from the learning set into a category and in this way learn a model. New datapoints will then fall in either category that has been developed based on the training set. Using this algorithm it is possible to draw a clear decision boundary. Different kernels can be used to fit a model. The options are linear, polynomial and RBF. The linear kernel fits a linear model to the data; the polynomial kernel fits a polynomial model, the RBF fits a radial basis function. \n",
    "\n",
    "In this problem we apply the algorithm with only 2 classes, but this can be adjusted to encompass multiple classes. \n",
    "\n",
    "C is the regularization parameter. It is set to 1 by default, however if the data has a lot of noise, the parameter should be decreased. We expect the data to have little noise as it is unlikely that passengers died of different causes than the sinking of the Titanic. We find that by increasing the regularization parameter, the fit of the model increases as measured by the .score . \n",
    "\n",
    "Gamma, defined in the RBF function is a parameter measuring how far the influence of one training example reaches. A low value for gamma means that the training example reaches far; a high value for gamma means the training example reached close. The parameter cannot be set to a negative value. Setting gamma too large will lead to overfitting. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The Linear Kernel\n",
    "\n",
    "C=2 #Regularization parameter\n",
    "\n",
    "clf_linear = svm.SVC(kernel='linear', C=C)\n",
    "clf_linear.fit(X_train, y_train)\n",
    "Y_pred = clf_linear.predict(X_test)\n",
    "acc_clf_linear = clf_linear.score(X_train, y_train)\n",
    "acc_clf_linear2 = cross_val_score(clf_linear,X_train, y_train)\n",
    "m_acc_clf_linear2 = acc_clf_linear2.mean()\n",
    "sd_acc_clf_linear2 = acc_clf_linear2.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The RBF Kernel\n",
    "\n",
    "C=2 #Regularization parameter\n",
    "\n",
    "clf_rbf = svm.SVC(kernel='rbf', gamma=0.3, C=C)\n",
    "clf_rbf.fit(X_train, y_train)\n",
    "Y_pred = clf_rbf.predict(X_test)\n",
    "acc_clf_rbf = clf_rbf.score(X_train, y_train)\n",
    "acc_clf_rbf2 = cross_val_score(clf_rbf,X_train, y_train)\n",
    "m_acc_clf_rbf2 = acc_clf_rbf2.mean()\n",
    "sd_acc_clf_rbf2 = acc_clf_rbf2.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEAREST NEIGHBOUR CLASSIFIER\n",
    "\n",
    "The Nearest Neighbour Classifier (KNN) will, for each new observation in the training data X, find the observation that is closest. In this sense the KNN is a distance based classifier. The KNN has low bias, but also high variance which increases the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "acc_knn = knn.score(X_train, y_train)\n",
    "acc_knn2 = cross_val_score(knn,X_train, y_train)\n",
    "m_acc_knn2 = acc_knn2.mean()\n",
    "sd_acc_knn2 = acc_knn2.std()\n",
    "\n",
    "# h = 0.2\n",
    "\n",
    "#x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "#y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "#xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "#                         np.arange(y_min, y_max, h))\n",
    "#Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    " #Put the result into a color plot\n",
    "#Z = Z.reshape(xx.shape)\n",
    "#plt.figure()\n",
    "#plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "# Plot also the training points\n",
    "#plt.scatter(X_train[:, 0], X[:, 1], c=y_train, cmap=cmap_bold)\n",
    "#plt.xlim(xx.min(), xx.max())\n",
    "#plt.ylim(yy.min(), yy.max())\n",
    "#plt.title(\"3-Class classification (k = %i, weights = '%s')\"\n",
    "\n",
    "#% (n_neighbors, weights))\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREES\n",
    "\n",
    "A decision tree is a classifier which maps observations based on characteristics. The learnt model can be represented as a tree where the observations or features about an training example are on the branches and the leaves are the class labels. Based on the model that is learnt in this manner, outcome for new data can be predicted. In the titanic problem, the different features are on the branches and the leaves represent the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DT = tree.DecisionTreeClassifier()\n",
    "DT.fit(X_train, y_train)\n",
    "Y_pred = DT.predict(X_test)\n",
    "acc_DT = DT.score(X_train, y_train)\n",
    "acc_DT2 = cross_val_score(DT, X_train, y_train)\n",
    "m_acc_DT2 = acc_DT2.mean()\n",
    "sd_acc_DT2 = acc_DT2.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST\n",
    "\n",
    "A random forest is a method where random samples are taken from the training data with replacement. As samples are drawn uniformly and with replacement, the different models defined in this way will be based on diverse samples where some training data might be used more than once, and some not at all. This method is also know as 'bagging' which is short for 'bootstrap sampling'. When bagging is combined with randomly selecting features to be used for a decision tree classifier, we start building a random forest. Randomly selecting features is also known as subspace sampling. The combination of subspace sampling and bagging induces great variety in the ensemble. The different trees created in this way together make up a random forest. \n",
    "\n",
    "Because of the manner in which the random forest algorithm works, the chance that it overfits the data is relatively slim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RFC = ensemble.RandomForestClassifier()\n",
    "RFC.fit(X_train, y_train)\n",
    "Y_pred = RFC.predict(X_test)\n",
    "acc_RFC = RFC.score(X_train, y_train)\n",
    "acc_RFC2 = cross_val_score(RFC, X_train, y_train)\n",
    "m_acc_RFC2 = acc_RFC2.mean()\n",
    "sd_acc_RFC2 = acc_RFC2.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTREME RANDOMIZED TREES\n",
    "\n",
    "Extreme Randomized Trees are similar to random forests in the way they are build. They make use of bagging and of subspace sampling. Where they differ is that, from the random selection of features included in each tree now the threshold in each feature is picked randomly (in the random forest this was done on best pick basis). In this way the variance is reduced a bit more but the bias increases a little bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ETC = ensemble.ExtraTreesClassifier()\n",
    "ETC.fit(X_train, y_train)\n",
    "Y_pred = ETC.predict(X_test)\n",
    "acc_ETC = ETC.score(X_train, y_train)\n",
    "acc_ETC2 = cross_val_score(RFC, X_train, y_train)\n",
    "m_acc_ETC2 = acc_ETC2.mean()\n",
    "sd_acc_ETC2 = acc_ETC2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVS_Mean</th>\n",
       "      <th>CVS_SD</th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.796857</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.813692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.015141</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.783389</td>\n",
       "      <td>0.025396</td>\n",
       "      <td>SVC RBF</td>\n",
       "      <td>0.928171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.781145</td>\n",
       "      <td>0.033445</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.795735</td>\n",
       "      <td>0.022221</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.959596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.015872</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.950617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.019244</td>\n",
       "      <td>Extreme Randomized Tree</td>\n",
       "      <td>0.959596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CVS_Mean    CVS_SD                    Model     Score\n",
       "0  0.796857  0.004199      Logistic Regression  0.813692\n",
       "1  0.802469  0.015141               Linear SVC  0.814815\n",
       "2  0.783389  0.025396                  SVC RBF  0.928171\n",
       "3  0.781145  0.033445                      KNN  0.851852\n",
       "4  0.795735  0.022221            Decision Tree  0.959596\n",
       "5  0.800224  0.015872            Random Forest  0.950617\n",
       "6  0.797980  0.019244  Extreme Randomized Tree  0.959596"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model' : ['Logistic Regression', 'Linear SVC', 'SVC RBF', 'KNN','Decision Tree','Random Forest','Extreme Randomized Tree'],\n",
    "    'Score' : [acc_log, acc_clf_linear, acc_clf_rbf, acc_knn, acc_DT, acc_RFC, acc_ETC],\n",
    "    'CVS_Mean' : [m_acc_log2, m_acc_clf_linear2, m_acc_clf_rbf2, m_acc_knn2, m_acc_DT2, m_acc_RFC2, m_acc_ETC2],\n",
    "    'CVS_SD' : [sd_acc_log2, sd_acc_clf_linear2, sd_acc_clf_rbf2, sd_acc_knn2, sd_acc_DT2, sd_acc_RFC2, sd_acc_ETC2]\n",
    "})\n",
    "models.sort_values(by='Score', ascending=False)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table we find that, based on the score algorithm, the Decision Tree and the Extreme Randomized Trees fit the training data equally well, in both cases almost 96% of the training examples are classified correctly. When looking at the average cross validation score for these two models, we see that the Extreme Randomized Tree performance best and on average classifies 80% of the data correctly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further ideas + things that need solving still\n",
    "\n",
    "- Using a confusion matrix to show how well the models fit the test data. In a confusion matrix, the values on the diagonal show the number of observations classified right, we want this to be as high as possible. \n",
    "- Work out a feature around the titles in the name variable using the str.extract as given below:\n",
    "        df_train['Title'] = df_train['Name'].str.extract('( [A-Za-z]+)\\.', expand=False)\n",
    "- Plot ticks on axes of correlation plot\n",
    "- Work a way around the 'ValueError: query data dimension must match training data dimension' when tryin to plot the decision boundary plot for the KNN classifier.  \n",
    "- Add SVC with polynomial kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### References\n",
    "\n",
    "Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n",
    "\n",
    "Various other notebooks created to solve the Titanic problem and other online sources. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
